{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import multiprocessing as mp\n",
    "from estival.wrappers import pymc as epm\n",
    "from estival.sampling import tools as esamp\n",
    "from estival.wrappers import nevergrad as eng\n",
    "from estival.utils.parallel import map_parallel\n",
    "import nevergrad as ng\n",
    "# from autumn.infrastructure.remote import springboard\n",
    "from tbdynamics.camau.calibration.utils import get_bcm\n",
    "from estival.utils.sample import SampleTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_configs = {\n",
    "        'no_covid': {\n",
    "            \"detection_reduction\": False,\n",
    "            \"contact_reduction\": False\n",
    "        },  # No reduction\n",
    "        'detection': {\n",
    "            \"detection_reduction\": True,\n",
    "            \"contact_reduction\": False\n",
    "        },  # No contact reduction\n",
    "        # 'contact': {\n",
    "        #     \"detection_reduction\": False,\n",
    "        #     \"contact_reduction\": True\n",
    "        # },  # Only contact reduction\n",
    "        # 'detection_and_contact': {\n",
    "        #     \"detection_reduction\": True,\n",
    "        #     \"contact_reduction\": True\n",
    "        # },  # With detection + contact reduction\n",
    "    }\n",
    "\n",
    "covid_effects = {\n",
    "    'detection_reduction':True,\n",
    "    'contact_reduction':False\n",
    "}\n",
    "params = {\n",
    "    \"start_population_size\": 30000.0,\n",
    "    \"seed_time\": 1805.0,\n",
    "    \"seed_num\": 1.0,\n",
    "    \"seed_duration\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(out_path, params, covid_effects, draws, tune):\n",
    "    bcm = get_bcm(params, covid_effects, homo_mixing=False)\n",
    "    def optimize_ng_with_idx(item):\n",
    "        idx, sample = item\n",
    "        opt = eng.optimize_model(bcm, budget=500, opt_class=ng.optimizers.TwoPointsDE, suggested = sample, num_workers=8)\n",
    "        rec= opt.minimize(500)\n",
    "        return idx, rec.value[1]\n",
    "\n",
    "    lhs_samples = bcm.sample.lhs(16, ci=0.67)\n",
    "    lhs_lle = esamp.likelihood_extras_for_samples(lhs_samples, bcm)\n",
    "    lhs_sorted = lhs_lle.sort_values(\"loglikelihood\", ascending=False)\n",
    "    opt_samples_idx = map_parallel(optimize_ng_with_idx, lhs_sorted.iterrows())\n",
    "    best_opt_samps = bcm.sample.convert(opt_samples_idx)\n",
    "    init_samps = best_opt_samps.convert(SampleTypes.LIST_OF_DICTS)[0:N_SAMPLES]\n",
    "    n_chains = N_SAMPLES\n",
    "    with pm.Model() as pm_model:\n",
    "        variables = epm.use_model(bcm)\n",
    "        idata_raw = pm.sample(\n",
    "            step=[pm.DEMetropolisZ(variables, proposal_dist=pm.NormalProposal)],\n",
    "            draws=draws,\n",
    "            cores= 16,\n",
    "            tune=tune,\n",
    "            discard_tuned_samples=False,\n",
    "            chains=n_chains,\n",
    "            progressbar=True,\n",
    "            initvals=init_samps,\n",
    "        )\n",
    "    idata_raw.to_netcdf(str(out_path / \"calib_full_out.nc\"))\n",
    "\n",
    "    # burnt_idata = idata_raw.sel(draw=np.s_[50000:])\n",
    "    # idata_extract = az.extract(burnt_idata, num_samples=n_samples)\n",
    "    # bcm.sample.convert(idata_extract).to_hdf5(out_path / \"calib_extract_out.h5\")\n",
    "\n",
    "    # spaghetti_res = esamp.model_results_for_samples(idata_extract, bcm)\n",
    "    # spaghetti_res.results.to_hdf(str(out_path / \"results.hdf\"), \"spaghetti\")\n",
    "\n",
    "    # like_df = esamp.likelihood_extras_for_idata(idata_raw, bcm)\n",
    "    # like_df.to_hdf(str(out_path / \"results.hdf\"), \"likelihood\")\n",
    "\n",
    "\n",
    "# def run_calibration(bridge: springboard.task.TaskBridge, bcm, draws, tune):\n",
    "#     import multiprocessing as mp\n",
    "#     mp.set_start_method(\"forkserver\")\n",
    "#     idata_raw = calibrate(bridge.out_path, bcm, draws, tune)\n",
    "#     bridge.logger.info(\"Calibration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_with_configs(out_path, params, covid_configs, draws, tune):\n",
    "    for config_name, covid_effects in covid_configs.items():\n",
    "        # Call the original calibrate function with each covid_effects\n",
    "        bcm = get_bcm(params, covid_effects)\n",
    "        \n",
    "        def optimize_ng_with_idx(item):\n",
    "            idx, sample = item\n",
    "            opt = eng.optimize_model(bcm, budget=500, opt_class=ng.optimizers.TwoPointsDE, suggested=sample, num_workers=8)\n",
    "            rec = opt.minimize(500)\n",
    "            return idx, rec.value[1]\n",
    "\n",
    "        lhs_samples = bcm.sample.lhs(16, ci=0.67)\n",
    "        lhs_lle = esamp.likelihood_extras_for_samples(lhs_samples, bcm)\n",
    "        lhs_sorted = lhs_lle.sort_values(\"loglikelihood\", ascending=False)\n",
    "        opt_samples_idx = map_parallel(optimize_ng_with_idx, lhs_sorted.iterrows())\n",
    "        best_opt_samps = bcm.sample.convert(opt_samples_idx)\n",
    "        init_samps = best_opt_samps.convert(SampleTypes.LIST_OF_DICTS)[0:4]\n",
    "        n_chains = 4\n",
    "        # n_samples = 1000\n",
    "        \n",
    "        with pm.Model() as pm_model:\n",
    "            variables = epm.use_model(bcm)\n",
    "            idata_raw = pm.sample(\n",
    "                step=[pm.DEMetropolisZ(variables)],\n",
    "                draws=draws,\n",
    "                cores=16,\n",
    "                tune=tune,\n",
    "                discard_tuned_samples=False,\n",
    "                chains=n_chains,\n",
    "                progressbar=True,\n",
    "                initvals=init_samps,\n",
    "            )\n",
    "        \n",
    "        # Save results using the configuration key in the filenames\n",
    "        idata_raw.to_netcdf(str(out_path / f\"calib_full_out_{config_name}.nc\"))\n",
    "        # burnt_idata = idata_raw.sel(draw=np.s_[5000:])\n",
    "        # idata_extract = az.extract(burnt_idata, num_samples=n_samples)\n",
    "        # bcm.sample.convert(idata_extract).to_hdf5(out_path / f\"calib_extract_out_{config_name}.h5\")\n",
    "        \n",
    "        # spaghetti_res = esamp.model_results_for_samples(idata_extract, bcm)\n",
    "        # spaghetti_res.results.to_hdf(str(out_path / f\"results_{config_name}.hdf\"), \"spaghetti\")\n",
    "        \n",
    "        # like_df = esamp.likelihood_extras_for_idata(idata_raw, bcm)\n",
    "        # like_df.to_hdf(str(out_path / f\"results_{config_name}.hdf\"), \"likelihood\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = OUT_PATH = Path.cwd().parent.parent / 'data/outputs/camau/r0203'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('e:/tbdynamics/data/outputs/camau/r0103')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 16 jobs)\n",
      "DEMetropolisZ: [contact_rate, rr_infection_latent, rr_infection_recovered, progression_multiplier, smear_positive_death_rate, smear_negative_death_rate, smear_positive_self_recovery, smear_negative_self_recovery, screening_scaleup_shape, screening_inflection_time, time_to_screening_end_asymp, acf_sensitivity, prop_mixing_same_stratum, detection_reduction, notif_dispersion, latent_dispersion, acf_detectionXact3_trial_dispersion, acf_detectionXact3_control_dispersion]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='30000' class='' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [30000/30000 19:22&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_500 tune and 5_000 draw iterations (10_000 + 20_000 draws total) took 1178 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    }
   ],
   "source": [
    "draws= 10000\n",
    "tune = 5000\n",
    "calibrate(OUT_PATH,params, covid_effects, draws, tune)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
